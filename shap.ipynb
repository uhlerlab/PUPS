{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d5ad501734842af81591055cfc25af9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "import torchvision\n",
    "import torch\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from src.model.full_model import SubCellProtModel\n",
    "from src.utils.data_handling_utils import initialize_datasets, Retrieval_Data\n",
    "from src.utils.batch_run_utils import batch_call, get_cell_lines_of_interest, get_isoforms_of_interest, get_proteoform_data\n",
    "from src.analysis.shapely_analysis import shapley_analysis_sliding_kernel_explainer\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from src.dataset.dataset import CLASSES\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "from enum import Enum\n",
    "import pdb\n",
    "import pickle as pk\n",
    "import math\n",
    "from numpy import savetxt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Image IDs & Splice_isoform ids for a joint embedding investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_NAME = \"splice_isoform_dataset_cell_line_and_gene_split_full\"\n",
    "RANDOM_COLLECTION_NAME=\"random_splice_isoform_dataset\"\n",
    "\n",
    "MODEL_CHECKPOINT = 'checkpoints/splice_isoform_dataset_cell_line_and_gene_split_full-epoch=01-val_combined_loss=0.18.ckpt'\n",
    "\n",
    "SLIDING_KERNEL_SIZE = 1  \n",
    "NSAMPLES = 10000  # 1000 # Number of samples to take per baseline protein\n",
    "NUM_BASELINE_PROTEINS = 300   # Number of baseline proteins to compare against\n",
    "TOTAL_SAMPLED_PROTEOFORMS = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset, get_data = initialize_datasets(COLLECTION_NAME, if_alphabetical=True)\n",
    "random_train_dataset, random_val_dataset, random_test_dataset, random_get_data = (\n",
    "    initialize_datasets(RANDOM_COLLECTION_NAME, if_alphabetical=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = SubCellProtModel().load_from_checkpoint(\n",
    "    MODEL_CHECKPOINT,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    batch_size=32,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to look up specific genes:\n",
    "1. First find the gene you want from the HPA website.\n",
    "2. Copy the ID from the URL e.g. https://www.proteinatlas.org/ENSG00000124608-AARS2\n",
    "3. Figure out whether the gene is in one of our two datasets. You can try:\n",
    "\n",
    "For genes in the training or holdout 1 dataset:\n",
    "* use_old_hpa_client=True \n",
    "* and use get_data()    \n",
    "\n",
    "Then for genes in the holdout 2 dataset:\n",
    "* use_old_hpa_client=False \n",
    "* and use random_get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteoforms_4_shap = [\n",
    "    # \"\"\" THESE ARE THE MITOCHONDRIA DATASET SAMPLES\"\"\"\n",
    "\n",
    "    # AARS2 ENSG00000124608\n",
    "    (get_proteoform_data(COLLECTION_NAME, get_data, gene_id=\"ENSG00000124608\", use_old_hpa_client=True), get_data),\n",
    "    # N4BP2\n",
    "    (get_proteoform_data(RANDOM_COLLECTION_NAME, random_get_data, gene_id='ENSG00000078177', use_old_hpa_client=False), random_get_data),\n",
    "    # DDIT3\n",
    "    (get_proteoform_data(COLLECTION_NAME, get_data, gene_id='ENSG00000175197', use_old_hpa_client=True), get_data),\n",
    "]\n",
    "proteoforms_4_shap_updated = []\n",
    "for metadata, data_source in proteoforms_4_shap:\n",
    "    _X_investigation, x_len_investigation = data_source(\n",
    "        metadata['_id'], retrieval_data=Retrieval_Data.PROTEIN_SEQ\n",
    "    )\n",
    "    proteoforms_4_shap_updated.append(\n",
    "        (\n",
    "            metadata['_id'], \n",
    "            x_len_investigation,\n",
    "            data_source\n",
    "        )\n",
    "    )\n",
    "proteoforms_4_shap_updated.sort(key = lambda x: x[1])\n",
    "proteoforms_4_shap = [element[0] for element in proteoforms_4_shap_updated ]\n",
    "data_sources = [element[2] for element in proteoforms_4_shap_updated ]\n",
    "proteoforms_4_shap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment out below if you just want results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gather baseline isoforms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████▊                                                      | 1570/9472 [00:53<04:36, 28.57it/s]"
     ]
    }
   ],
   "source": [
    "print(\"gather baseline isoforms\")\n",
    "baseline_isoforms = get_isoforms_of_interest_new(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    total_investigated_isoforms=TOTAL_SAMPLED_PROTEOFORMS,\n",
    "    get_data=get_data,\n",
    "    seed=0,\n",
    "    use_old_hpa_client=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter\n",
    "import matplotlib\n",
    "\n",
    "# Ensure SciencePlots is installed\n",
    "try:\n",
    "    import scienceplots\n",
    "except ImportError:\n",
    "    print(\"scienceplots is not installed. Please install it using `pip install SciencePlots`.\")\n",
    "\n",
    "# Set SciencePlots style\n",
    "plt.style.use(['science', 'no-latex'])\n",
    "\n",
    "def viz_shapely_helper(\n",
    "    TARGET_ISOFORM_FOR_SHAP,\n",
    "    compartment_name,\n",
    "    x_len_investigation,\n",
    "    ax,\n",
    "    sigma=100,\n",
    "    x_axis_title=\"Residue Index\",\n",
    "    aggregate_type=\"savgol_filter\",\n",
    "):\n",
    "    fixed_compartment_idx = sorted(CLASSES[0]).index(compartment_name)\n",
    "    bad_compartment_name = CLASSES[0][fixed_compartment_idx]\n",
    "    filename = f\"high_fidelity_joint_background_{TARGET_ISOFORM_FOR_SHAP}_{bad_compartment_name}_({fixed_compartment_idx}).csv\"\n",
    "    print(filename)\n",
    "    shap_values = pd.read_csv(filename, header=None).to_numpy()[0]\n",
    "\n",
    "    if aggregate_type == \"sliding_gaussian\":\n",
    "        def gaussian_kernel_1d(sigma):\n",
    "            kernel_radius = np.ceil(sigma) * 3\n",
    "            kernel_size = kernel_radius * 2 + 1\n",
    "            ax = np.arange(-kernel_radius, kernel_radius + 1.0, dtype=np.float32)\n",
    "            kernel = np.exp(-(ax**2) / (2.0 * sigma**2))\n",
    "            return (kernel / np.sum(kernel)).reshape(1, kernel.shape[0])\n",
    "\n",
    "        kernel = gaussian_kernel_1d(sigma)[0]\n",
    "        sliding_window = np.convolve(shap_values, kernel, mode=\"full\")\n",
    "    elif aggregate_type == \"sliding_ones\":\n",
    "        kernel = np.ones(20) / 20\n",
    "        sliding_window = np.convolve(shap_values, kernel, mode=\"full\")\n",
    "    elif aggregate_type == \"savgol_filter\":\n",
    "        sliding_window = savgol_filter(shap_values, window_length=51, polyorder=2)\n",
    "\n",
    "    target_x_len = int(x_len_investigation / SLIDING_KERNEL_SIZE)\n",
    "    x_vals = [SLIDING_KERNEL_SIZE * x for x in list(range(target_x_len))]\n",
    "    \n",
    "    # Set colors based on compartment name\n",
    "    if compartment_name.lower() == \"nucleoplasm\":\n",
    "        background_color = 'pink'\n",
    "        foreground_color = 'red'\n",
    "    elif compartment_name.lower() == \"cytosol\":\n",
    "        background_color = 'peachpuff'\n",
    "        foreground_color = 'orange'\n",
    "    else:\n",
    "        background_color = 'lightblue'\n",
    "        foreground_color = 'blue'\n",
    "    \n",
    "    # Plot histogram\n",
    "    ax.bar(x_vals, shap_values[:target_x_len], width=SLIDING_KERNEL_SIZE, color=background_color, alpha=0.7)\n",
    "    \n",
    "    # Plot smoothed line\n",
    "    ax.plot(\n",
    "        x_vals,\n",
    "        sliding_window[:target_x_len],\n",
    "        color=foreground_color,\n",
    "        linewidth=2.5,\n",
    "    )\n",
    "    \n",
    "    ax.set_title(compartment_name)\n",
    "    ax.set_xlabel(x_axis_title)\n",
    "\n",
    "def viz_shapely(\n",
    "    TARGET_ISOFORM_FOR_SHAP,\n",
    "    X_investigation,\n",
    "    x_len_investigation,\n",
    "    X_landmark_stains,\n",
    "    compartments=CLASSES[0],\n",
    "    num_cols=5,\n",
    "    get_data=get_data\n",
    "):\n",
    "    fig, ax = plt.subplots(\n",
    "        figsize=(4, 1.5),\n",
    "    )\n",
    "    fig.tight_layout()  # Adjust spacing between subplots\n",
    "\n",
    "    # Iterate over compartments and corresponding subplot\n",
    "    for compartment in compartments:\n",
    "        viz_shapely_helper(\n",
    "            TARGET_ISOFORM_FOR_SHAP=TARGET_ISOFORM_FOR_SHAP,\n",
    "            compartment_name=compartment,\n",
    "            x_len_investigation=x_len_investigation,  # Adjust as needed\n",
    "            ax=ax,\n",
    "            sigma=0.5,\n",
    "            x_axis_title=\"Residue Index\",\n",
    "        )\n",
    "\n",
    "    (\n",
    "        _y_pred_antibody_stain,\n",
    "        y_pred_multilabel,\n",
    "        _y_pred_multilabel_raw,\n",
    "    ) = loaded_model.predict_step(\n",
    "        (\n",
    "            X_investigation.unsqueeze(0),\n",
    "            torch.Tensor([x_len_investigation]),\n",
    "            torch.Tensor(X_landmark_stains).unsqueeze(0),\n",
    "            None,\n",
    "            None,\n",
    "        ),\n",
    "        batch_idx=0,\n",
    "    )\n",
    "    assert len(sorted(CLASSES[0])) == len(y_pred_multilabel[0])\n",
    "    pred_location_labels = [\n",
    "        compartment\n",
    "        for compartment, y_pred in zip(sorted(CLASSES[0]), y_pred_multilabel[0])\n",
    "        if y_pred\n",
    "    ]\n",
    "    metadata = get_data(TARGET_ISOFORM_FOR_SHAP, retrieval_data=Retrieval_Data.METADATA)\n",
    "\n",
    "    plt.suptitle(\n",
    "        f\"Shapely Analysis [Averaged] for {metadata['splice_isoform_id']} \\n(True: {metadata['location_labels']}, Pred: {pred_location_labels})\",\n",
    "        y=1.98,\n",
    "    )\n",
    "    plt.subplots_adjust(top=1.5, left=0.10)  # Increase the top spacing\n",
    "\n",
    "#     plt.show()\n",
    "    plt.savefig(\n",
    "        f\"Shapely Analysis [Averaged] for {metadata['splice_isoform_id']} (True: {metadata['location_labels']}, Pred: {pred_location_labels})\"+'.pdf'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_shap_analysis(\n",
    "    TARGET_ISOFORM_FOR_SHAP,\n",
    "    model,\n",
    "    baseline_Xs,\n",
    "    target_X,\n",
    "    target_x_lens,\n",
    "    target_X_landmark_stains,\n",
    "    nsamples=200,\n",
    "    kernel_size=1,\n",
    "):\n",
    "    assert len(target_X) == 1, (\n",
    "        \"Can only compute single protein target\"\n",
    "    )\n",
    "    model.eval()\n",
    "\n",
    "    nucleoplasm_savename = f\"high_fidelity_joint_background_{TARGET_ISOFORM_FOR_SHAP}_{CLASSES[0][0]}_({0}).csv\"\n",
    "    if os.path.exists(nucleoplasm_savename):\n",
    "        return None\n",
    "\n",
    "    res = shapley_analysis_sliding_kernel_explainer(\n",
    "        model=model,\n",
    "        baseline_Xs=baseline_Xs,\n",
    "        target_X=target_X,\n",
    "        target_x_lens=target_x_lens,\n",
    "        target_X_landmark_stains=target_X_landmark_stains,\n",
    "        kernel_size=kernel_size,\n",
    "        nsamples=nsamples,\n",
    "    )\n",
    "\n",
    "    expected_vals = res[1]\n",
    "    print(\"expected vals for the different compartments: \", expected_vals)\n",
    "    compartment_shap_vals = [shap_vals for shap_vals in res[0]]\n",
    "    [\n",
    "        savetxt(\n",
    "            f\"high_fidelity_joint_background_{TARGET_ISOFORM_FOR_SHAP}_{CLASSES[0][compartment_idx]}_({compartment_idx}).csv\",\n",
    "            comp_shap,\n",
    "            delimiter=\",\",\n",
    "        )\n",
    "        for compartment_idx, comp_shap in enumerate(compartment_shap_vals)\n",
    "    ]\n",
    "    return expected_vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_shap_analysis(\n",
    "    TARGET_ISOFORM_FOR_SHAP, \n",
    "    TARGET_CELL_IMAGE_FOR_SHAP, \n",
    "    baseline_isoforms, \n",
    "    data_source=None,\n",
    "    run_just_one_average_background=True,\n",
    "):\n",
    "    if data_source is None:\n",
    "        data_source = get_data\n",
    "\n",
    "    X_investigation, x_len_investigation = data_source(\n",
    "        TARGET_ISOFORM_FOR_SHAP, retrieval_data=Retrieval_Data.PROTEIN_SEQ\n",
    "    )\n",
    "    X_landmark_stains = data_source(\n",
    "        TARGET_CELL_IMAGE_FOR_SHAP, retrieval_data=Retrieval_Data.CELL_IMAGE\n",
    "    )\n",
    "\n",
    "    filtered_baseline_isoforms = []\n",
    "    full_baseline_isoforms = []\n",
    "    averaged_baseline_X = torch.zeros(X_investigation.shape)\n",
    "\n",
    "    for isoform in tqdm(baseline_isoforms):\n",
    "        if len(isoform.split(\" \")) < 2:\n",
    "            continue\n",
    "        X, x_len = get_data(\n",
    "            isoform.split(\" \")[1], retrieval_data=Retrieval_Data.PROTEIN_SEQ\n",
    "        )\n",
    "        if x_len < x_len_investigation:\n",
    "            # Skipping all isoforms which are smaller than our target isoform in our baseline\n",
    "            # Because otherwise we can't \"replace\" the amino acid at end of our target sequence\n",
    "            # with a residue from the baseline isoform.\n",
    "            continue\n",
    "        averaged_baseline_X += X\n",
    "        filtered_baseline_isoforms.append(isoform.split(\" \")[1])\n",
    "        if not run_just_one_average_background:\n",
    "            full_baseline_isoforms.append(X)\n",
    "    if not run_just_one_average_background:\n",
    "        full_baseline_isoforms = np.stack(full_baseline_isoforms)\n",
    "        full_baseline_isoforms = full_baseline_isoforms[\n",
    "            : min(len(full_baseline_isoforms), NUM_BASELINE_PROTEINS)\n",
    "        ]\n",
    "        print(f\"total number of isoforms: {len(full_baseline_isoforms)}\")\n",
    "\n",
    "    print(\n",
    "        f\"total samples in our baseline (that pass the length check): {len(filtered_baseline_isoforms)}\"\n",
    "    )\n",
    "    print(filtered_baseline_isoforms)\n",
    "\n",
    "    if run_just_one_average_background:\n",
    "        averaged_baseline_X /= len(filtered_baseline_isoforms)\n",
    "        full_baseline_isoforms = np.stack([averaged_baseline_X])\n",
    "\n",
    "    expected_vals = perform_shap_analysis(\n",
    "        TARGET_ISOFORM_FOR_SHAP=TARGET_ISOFORM_FOR_SHAP,\n",
    "        model=loaded_model,\n",
    "        baseline_Xs=full_baseline_isoforms,\n",
    "        target_X=X_investigation,\n",
    "        target_x_lens=[x_len_investigation],\n",
    "        target_X_landmark_stains=X_landmark_stains,\n",
    "        nsamples=NSAMPLES,\n",
    "        kernel_size=SLIDING_KERNEL_SIZE,\n",
    "    )\n",
    "\n",
    "\n",
    "    viz_shapely(\n",
    "        TARGET_ISOFORM_FOR_SHAP=TARGET_ISOFORM_FOR_SHAP,\n",
    "        X_investigation=X_investigation,\n",
    "        x_len_investigation=x_len_investigation,\n",
    "        X_landmark_stains=X_landmark_stains,\n",
    "        compartments=[\"Nucleoplasm\", \"Cytosol\", \"Mitochondria\"],\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for proteoform_idx in proteoforms_4_shap:\n",
    "    average_shap_analysis(proteoform_idx, proteoform_idx, baseline_isoforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for proteoform_idx in proteoforms_4_shap:\n",
    "    X_investigation, x_len_investigation = get_data(\n",
    "        proteoform_idx, retrieval_data=Retrieval_Data.PROTEIN_SEQ\n",
    "    )\n",
    "    X_landmark_stains = get_data(\n",
    "        proteoform_idx, retrieval_data=Retrieval_Data.CELL_IMAGE\n",
    "    )\n",
    "    \n",
    "    viz_shapely(\n",
    "        TARGET_ISOFORM_FOR_SHAP=proteoform_idx,\n",
    "        X_investigation=X_investigation,\n",
    "        x_len_investigation=x_len_investigation,\n",
    "        X_landmark_stains=X_landmark_stains,\n",
    "        compartments=[\"Nucleoplasm\", \"Cytosol\", \"Mitochondria\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for proteoform_idx in proteoforms_4_shap:\n",
    "    X_investigation, x_len_investigation = random_get_data(\n",
    "        proteoform_idx, retrieval_data=Retrieval_Data.PROTEIN_SEQ\n",
    "    )\n",
    "    X_landmark_stains = random_get_data(\n",
    "        proteoform_idx, retrieval_data=Retrieval_Data.CELL_IMAGE\n",
    "    )\n",
    "    \n",
    "    viz_shapely(\n",
    "        TARGET_ISOFORM_FOR_SHAP=proteoform_idx,\n",
    "        X_investigation=X_investigation,\n",
    "        x_len_investigation=x_len_investigation,\n",
    "        X_landmark_stains=X_landmark_stains,\n",
    "        compartments=[\"Nucleoplasm\", \"Cytosol\", \"Mitochondria\"],get_data=random_get_data\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1772.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_len_investigation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subcell",
   "language": "python",
   "name": "subcell_loc2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3c125f02d36538f8ba01dcae2421218f11ddabbbc44a777fee554ccc32fc7e77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
